{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectorData():\n",
    "    \n",
    "    source_feature = '' #путь до файла с фичами\n",
    "    source_dataset = '' #путь до файла с id, vas_id, buy_time\n",
    "    dest_dataset = '' #путь до файла результата\n",
    "    \n",
    "    cache_directory = '' #директория для временных файлов \n",
    "    \n",
    "    use_cache = False\n",
    "    is_train = True\n",
    "    \n",
    "    template_cache_files=''\n",
    "    \n",
    "    df_source_dataset = None\n",
    "    df_dest_dataset = None\n",
    "    \n",
    "    def __init__( self, source_dataset, source_feature, dest_dataset, cache_directory, use_cache=False, is_train=True):\n",
    "        self.source_dataset = source_dataset\n",
    "        self.source_feature = source_feature\n",
    "        self.dest_dataset = dest_dataset\n",
    "        self.cache_directory = cache_directory\n",
    "        self.use_cache = use_cache\n",
    "        self.is_train = is_train\n",
    "        self.template_cache_files = f'{self.cache_directory}/*_temp.csv'\n",
    "\n",
    "        \n",
    "    def __read_dataset(self):\n",
    "        self.df_source_dataset = dd.read_csv(self.source_dataset, sep=',')\n",
    "        self.df_source_dataset = self.df_source_dataset.rename(columns={'Unnamed: 0':'key_t'})\n",
    "    \n",
    "    def __read_feature(self):\n",
    "        df_feats = dd.read_csv(self.source_feature, sep='\\t')\n",
    "        df_feats = df_feats.rename(columns={'Unnamed: 0':'key_f', 'buy_time':'feat_time'})\n",
    "        return df_feats\n",
    "        \n",
    "    def file_index(self, i):\n",
    "        return f'{i:03}'\n",
    "    \n",
    "    def __create_cache_directory(self):\n",
    "        if not os.path.exists(self.cache_directory):\n",
    "            os.mkdir(self.cache_directory)\n",
    "        else:\n",
    "            shutil.rmtree(self.cache_directory, ignore_errors=True)\n",
    "            os.mkdir(self.cache_directory)            \n",
    "            \n",
    "    def __create_cache(self):\n",
    "        if self.df_source_dataset is None:\n",
    "            self.__read_dataset()\n",
    "        df_feats =  self.__read_feature()\n",
    "        df_result = dd.merge(self.df_source_dataset, df_feats, how='inner', left_on=['id'], right_on=['id'])\n",
    "        self.__create_cache_directory()\n",
    "        df_result.to_csv(self.template_cache_files , index=False, compute=True, name_function=self.file_index)\n",
    "        del df_feats, df_result\n",
    "        \n",
    "    def __group_columns(self):\n",
    "        if self.is_train:\n",
    "            return ['key_t', 'id','vas_id','buy_time', 'target']\n",
    "        else:\n",
    "            return ['key_t', 'id','vas_id','buy_time']\n",
    "        \n",
    "    def __check_datasets(self):\n",
    "        if (self.df_dest_dataset.shape[0]).compute() == (self.df_source_dataset.shape[0]).compute():\n",
    "            print(f'Количество строк соответствует в датасетах')\n",
    "            return True\n",
    "        else:\n",
    "            print(f'Количество строк НЕ СООТВЕТСВУЕТ в датасетах')\n",
    "            return False\n",
    "        \n",
    "    def __merge_datasets(self):\n",
    "        group_columns = self.__group_columns() #колонки слияний и группировок\n",
    "        df = dd.read_csv(self.template_cache_files) #чтение временных Файлов соответствующих исходному датасету по id\n",
    "        \n",
    "        df['diff'] = np.abs(df['buy_time'] - df['feat_time']) # находим абсалютное отклонение даты предложения услуги и профиля\n",
    "        \n",
    "        #поиск минимального отклонения\n",
    "        df_aggregation = df.groupby(group_columns)['diff'].min() \n",
    "        df = dd.merge(df, df_aggregation, on=group_columns, how='left', suffixes=('','_min'))\n",
    "        df = df[df['diff']==df['diff_min']] \n",
    "        \n",
    "        #оставляем только с минимальный отклонением или одну из двух минимальных дат, которая наступила раньше.\n",
    "        df = dd.merge(self.df_source_dataset,df, on=group_columns, how='left')\n",
    "        df_aggregation = df.groupby(group_columns)['diff_min'].count()\n",
    "        df = dd.merge(df,df_aggregation, how='left', on=group_columns, suffixes=('','_count'))    \n",
    "        df = df[np.logical_or((df['diff_min_count']==1),((df['buy_time']-df['feat_time'])>0))]\n",
    "        self.df_dest_dataset = df.drop(columns=['diff_min', 'diff_min_count'], axis=1)\n",
    "        del df , df_aggregation\n",
    "        \n",
    "    def transform(self, npartitions=1):\n",
    "        if self.use_cache:\n",
    "            self.__read_dataset()\n",
    "        else:\n",
    "            self.__create_cache()\n",
    "        self.__merge_datasets()\n",
    "        if self.__check_datasets():\n",
    "            self.df_dest_dataset = self.df_dest_dataset.repartition(npartitions=npartitions)\n",
    "            self.df_dest_dataset.to_csv(self.dest_dataset, index=False, compute=True, name_function=self.file_index)\n",
    "            print(f'{self.dest_dataset} сохранен')\n",
    "        return self.df_dest_dataset\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк соответствует в датасетах\n",
      "train_dataset/*_train.csv сохранен\n",
      "Wall time: 1h 8min 2s\n"
     ]
    }
   ],
   "source": [
    "SOURCE_FEATURES = 'features.csv'\n",
    "SOURCE_DATASET = 'data_train.csv'\n",
    "DEST_DATASET = 'train_dataset/*_train.csv'\n",
    "CACHE_DIRECTORY = 'train_temp_csv'\n",
    "\n",
    "cl_select_train = SelectorData(SOURCE_DATASET,SOURCE_FEATURES, DEST_DATASET, CACHE_DIRECTORY, use_cache=True)\n",
    "%time df = cl_select_train.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cl_select_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк соответствует в датасетах\n",
      "test_dataset/*_test.csv сохранен\n",
      "Wall time: 17min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_t</th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>key_f</th>\n",
       "      <th>feat_time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>406253</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>2087733</td>\n",
       "      <td>1533502800</td>\n",
       "      <td>-94.679971</td>\n",
       "      <td>113.010888</td>\n",
       "      <td>-108.620786</td>\n",
       "      <td>60.403202</td>\n",
       "      <td>...</td>\n",
       "      <td>-315.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>42.369552</td>\n",
       "      <td>-241.747724</td>\n",
       "      <td>-25.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>2806263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1547413200</td>\n",
       "      <td>1176267</td>\n",
       "      <td>1541365200</td>\n",
       "      <td>349.810029</td>\n",
       "      <td>355.280888</td>\n",
       "      <td>335.869214</td>\n",
       "      <td>302.673202</td>\n",
       "      <td>...</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-18.996269</td>\n",
       "      <td>-22.630448</td>\n",
       "      <td>-282.747724</td>\n",
       "      <td>-24.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329</td>\n",
       "      <td>3641829</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>4129269</td>\n",
       "      <td>1534712400</td>\n",
       "      <td>26.060029</td>\n",
       "      <td>118.010888</td>\n",
       "      <td>12.119214</td>\n",
       "      <td>77.263202</td>\n",
       "      <td>...</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-306.747724</td>\n",
       "      <td>-25.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>706</td>\n",
       "      <td>631009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>3195637</td>\n",
       "      <td>1533502800</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-111.569112</td>\n",
       "      <td>-110.740786</td>\n",
       "      <td>-164.176798</td>\n",
       "      <td>...</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-33.630448</td>\n",
       "      <td>-269.747724</td>\n",
       "      <td>-24.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-11.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1524</td>\n",
       "      <td>3303517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>1198007</td>\n",
       "      <td>1544994000</td>\n",
       "      <td>26.080029</td>\n",
       "      <td>-81.229112</td>\n",
       "      <td>12.139214</td>\n",
       "      <td>-47.416798</td>\n",
       "      <td>...</td>\n",
       "      <td>2350.229208</td>\n",
       "      <td>-10.996269</td>\n",
       "      <td>-22.630448</td>\n",
       "      <td>5486.252276</td>\n",
       "      <td>13.167111</td>\n",
       "      <td>1.305572</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3024000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_t       id  vas_id    buy_time    key_f   feat_time           0  \\\n",
       "0    116   406253     8.0  1546808400  2087733  1533502800  -94.679971   \n",
       "1    199  2806263     2.0  1547413200  1176267  1541365200  349.810029   \n",
       "2    329  3641829     5.0  1548018000  4129269  1534712400   26.060029   \n",
       "3    706   631009     2.0  1546808400  3195637  1533502800  -96.799971   \n",
       "4   1524  3303517     1.0  1548018000  1198007  1544994000   26.080029   \n",
       "\n",
       "            1           2           3  ...          244        245        246  \\\n",
       "0  113.010888 -108.620786   60.403202  ...  -315.770792 -25.996269  42.369552   \n",
       "1  355.280888  335.869214  302.673202  ...  -613.770792 -18.996269 -22.630448   \n",
       "2  118.010888   12.119214   77.263202  ...  -613.770792 -25.996269 -37.630448   \n",
       "3 -111.569112 -110.740786 -164.176798  ...  -613.770792 -25.996269 -33.630448   \n",
       "4  -81.229112   12.139214  -47.416798  ...  2350.229208 -10.996269 -22.630448   \n",
       "\n",
       "           247        248       249        250      251  252      diff  \n",
       "0  -241.747724 -25.832889 -0.694428 -12.175933 -0.45614  0.0  13305600  \n",
       "1  -282.747724 -24.832889 -0.694428 -12.175933 -0.45614  1.0   6048000  \n",
       "2  -306.747724 -25.832889 -0.694428 -12.175933 -0.45614  0.0  13305600  \n",
       "3  -269.747724 -24.832889 -0.694428 -11.175933 -0.45614  0.0  13305600  \n",
       "4  5486.252276  13.167111  1.305572 -12.175933 -0.45614  0.0   3024000  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_FEATURES = 'features.csv'\n",
    "SOURCE_DATASET = 'data_test.csv'\n",
    "DEST_DATASET = 'test_dataset/*_test.csv'\n",
    "CACHE_DIRECTORY = 'test_temp_csv'\n",
    "\n",
    "cl_select_train = SelectorData(SOURCE_DATASET,SOURCE_FEATURES, DEST_DATASET, CACHE_DIRECTORY, is_train=False)\n",
    "%time df=cl_select_train.transform()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del cl_select_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
